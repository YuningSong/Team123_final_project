{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project\n",
    "## NBA Player's statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract \n",
    "The topic is about NBA players’ personal information (Name, Age, Height, Weight…etc.) and statistics of regular season (PTS, RPG...etc.) which are scraped from the Internet (NBA official website, ESPN.com, Kaggle), and also including the social media (Instagram, Twitter, YouTube, Reddit ) data at this time. The basic conceptual model with the relationships of each entity is represented on ER diagrams. In addition, the SQL database for NBA data will be built for the user to search, providing some user cases to identify such database can be queried. Our database not only can be used to analyze the performance of each player and predict their following performance, but also can help to analyze their life through different social media."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from instaloader import Instaloader, Profile\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import dropwhile, takewhile\n",
    "from itertools import islice\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(2015,2018):\n",
    "    ## Web Scraper\n",
    "    url = \"http://www.espn.com/nba/statistics/player/_/stat/rebounds/sort/avgRebounds/year/\"+str(m)+\"/seasontype/2/count/\"+\"1\"\n",
    "    response = get(url)\n",
    "    html_soup = bs(response.text,'html.parser')## python's in built library HTML parser\n",
    "    id_check = html_soup.find(id =\"my-players-table\")\n",
    "\n",
    "    # find and store the max. page number\n",
    "    players_container2 = id_check.find_all(class_ =\"page-numbers\")\n",
    "    container2=players_container2[0].text\n",
    "    x = container2.split(\" \", 2) # split page \"1 of 7\" in to \"1\", \"of\", \"7\"\n",
    "    pages=int(x[2]) # get max page no.\"7\"\n",
    "\n",
    "    #nba1=pd.DataFrame() # store the data value in dataframe\n",
    "    globals()['nba1%s' % m] = pd.DataFrame()\n",
    "\n",
    "    for y in range(pages): # from page 1 to 7\n",
    "        url = \"http://www.espn.com/nba/statistics/player/_/stat/rebounds/sort/avgRebounds/year/\"+str(m)+\"/seasontype/2/count/\" + str(y*40+1)\n",
    "        response = get(url)\n",
    "        html_soup = bs(response.text, 'html.parser')  ## python's in built library HTML parser\n",
    "        id_check = html_soup.find(id=\"my-players-table\")\n",
    "        players_container = id_check.find_all(\"tr\")\n",
    "\n",
    "        headers1_cols = [] # store the headers for column\n",
    "        h_count=0 # for counting how many header repeat in each page\n",
    "        d_count=1 # for counting the rank of players\n",
    "\n",
    "        # extract data from individual players container\n",
    "        for container in players_container:\n",
    "            content = container.find_all(\"td\")\n",
    "            if content[0].text==\"RK\":\n",
    "                headers1_cols=[content[0].text, content[1].text, content[2].text,\n",
    "                              content[3].text, content[4].text, content[5].text,\n",
    "                              content[6].text, content[7].text, content[8].text,\n",
    "                              content[9].text, content[10].text, content[11].text]\n",
    "                h_count=h_count+1\n",
    "            else:\n",
    "                content_s=content[1].text.split(\",\",1)  #split player's name and position\n",
    "                tt = pd.DataFrame(np.column_stack([(y*40-h_count+d_count), content_s[0],content_s[1], content[2].text,\n",
    "                                                    content[3].text, content[4].text, content[5].text,\n",
    "                                                    content[6].text, content[7].text, content[8].text,\n",
    "                                                    content[9].text, content[10].text, content[11].text]))\n",
    "                globals()['nba1%s' % m]=globals()['nba1%s' % m].append(tt)\n",
    "            d_count=d_count+1\n",
    "\n",
    "    headers1_cols.insert(2,\"POSITION\") # add column \"POSITION\" in existing column list\n",
    "    globals()['nba1%s' % m].columns = headers1_cols # change the columns name to headers\n",
    "    globals()['nba1%s' % m].index = range(0,len(globals()['nba1%s' % m])) # reorder the index\n",
    "    \n",
    "\n",
    "    ## WebAPI\n",
    "    # fake a browser visit\n",
    "    user_agent = 'User-Agent: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Maxthon 2.0)'\n",
    "    headers = {'User-Agent':user_agent}\n",
    "    url='https://stats.nba.com/stats/leagueLeaders?LeagueID=00&PerMode=PerGame&Scope=S&Season='+ str(m-1)+'-'+str(m-2000)+'&SeasonType=Regular+Season&StatCategory=PTS'\n",
    "    r=requests.get(url,headers=headers).json() #grab the statistics data\n",
    "\n",
    "    num=int(len(r['resultSet']['rowSet'])) # numbers of total data\n",
    "\n",
    "    headers2_cols=[] # store the headers for column\n",
    "    #nba2=pd.DataFrame() # store the data value in dataframe\n",
    "    globals()['nba2%s' % m] = pd.DataFrame()\n",
    "\n",
    "    # store the headers for column\n",
    "    for x in r['resultSet']['headers']:\n",
    "        headers2_cols.append(x)\n",
    "\n",
    "    # extract data from json\n",
    "    for z in range(num):\n",
    "        player = pd.DataFrame([r['resultSet']['rowSet'][z]])\n",
    "        globals()['nba2%s' % m]=globals()['nba2%s' % m].append((player))\n",
    "\n",
    "    globals()['nba2%s' % m].columns=headers2_cols # change the columns name to headers\n",
    "    globals()['nba2%s' % m].index = range(0,num) # reorder the index\n",
    "\n",
    "\n",
    "## Import csv file\n",
    "nba3 = pd.read_csv(\"players_stats.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(2015,2018):\n",
    "    \n",
    "    #list to store scraped value data in:\n",
    "    combine1=pd.DataFrame()\n",
    "    combine2=pd.DataFrame()\n",
    "    player_stat_all=pd.DataFrame()\n",
    "    #player_stat=pd.DataFrame()\n",
    "    globals()['player_stat%s' % m] = pd.DataFrame()\n",
    "\n",
    "    # combine 3 dataframes by \"Player's Name\"\n",
    "    combine1=globals()['nba1%s' % m].merge(globals()['nba2%s' % m],left_on = 'PLAYER',right_on = 'PLAYER',how = 'inner')\n",
    "    combine2=nba3.merge(combine1,left_on = 'Name',right_on = 'PLAYER',how = 'inner')\n",
    "    combine2\n",
    "    \n",
    "    # pick the columns that needs to present and store them to new dataframe\n",
    "    player_stat_all = combine2[['Name','Age','Birth_Place','Birthdate','Height','Weight','TEAM_y','POSITION','PTS_y','RPG','AST_y','STL_y','BLK_y','TOV_y']]\n",
    "\n",
    "    # drop the rows that the values are missing\n",
    "    globals()['player_stat%s' % m] = player_stat_all.dropna()\n",
    "    # rename the columns' name\n",
    "    globals()['player_stat%s' % m].columns = ['Name', 'Age','Birth_Place','Birthdate','Height','Weight','Team','Position','PTS','RPG','AST','STL','BLK','TOV']\n",
    "\n",
    "    # change column \"Age\" type to int\n",
    "    globals()['player_stat%s' % m] = globals()['player_stat%s' % m].astype({'Age':'int'})\n",
    "\n",
    "    # reorder the index\n",
    "    globals()['player_stat%s' % m].index = range(0,len(globals()['player_stat%s' % m]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instagram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player_id</th>\n",
       "      <th>Name</th>\n",
       "      <th>ig_fullname</th>\n",
       "      <th>ig_username</th>\n",
       "      <th>ig_id</th>\n",
       "      <th>ig_bio</th>\n",
       "      <th>ig_url</th>\n",
       "      <th>ig_posts</th>\n",
       "      <th>ig_followers</th>\n",
       "      <th>ig_following</th>\n",
       "      <th>ig_latestpost_time</th>\n",
       "      <th>ig_latestpost_caption</th>\n",
       "      <th>ig_latestpost_likes</th>\n",
       "      <th>ig_latestpost_comments</th>\n",
       "      <th>ig_postwithin24hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Al Horford</td>\n",
       "      <td>Al Horford</td>\n",
       "      <td>alhorford</td>\n",
       "      <td>10733526</td>\n",
       "      <td></td>\n",
       "      <td>https://www.youtube.com/watch?v=YiZUWssMzyg&amp;fe...</td>\n",
       "      <td>325</td>\n",
       "      <td>510621</td>\n",
       "      <td>265</td>\n",
       "      <td>2019-04-21 23:13:57</td>\n",
       "      <td>Well done. On to the next challenge. Go Celtic...</td>\n",
       "      <td>21707</td>\n",
       "      <td>214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Alan Anderson</td>\n",
       "      <td>Alan Anderson</td>\n",
       "      <td>dubblea74</td>\n",
       "      <td>1923491235</td>\n",
       "      <td>Proud Father✊🏾\\n👨🏾‍🎓Michigan State Alumni\\n Hu...</td>\n",
       "      <td>https://thecombinelasvegas.com/</td>\n",
       "      <td>80</td>\n",
       "      <td>5393</td>\n",
       "      <td>43</td>\n",
       "      <td>No post in 24 hours</td>\n",
       "      <td>No post in 24 hours</td>\n",
       "      <td>No post in 24 hours</td>\n",
       "      <td>No post in 24 hours</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Alex Len</td>\n",
       "      <td>Alex Len</td>\n",
       "      <td>alexlen_21</td>\n",
       "      <td>300139600</td>\n",
       "      <td>Ukraine ✈️Maryland ✈️Phoenix ✈️Atlanta   \"A mo...</td>\n",
       "      <td>None</td>\n",
       "      <td>158</td>\n",
       "      <td>40823</td>\n",
       "      <td>1038</td>\n",
       "      <td>2019-04-22 02:56:56</td>\n",
       "      <td>Somewhere in Barcelona</td>\n",
       "      <td>1688</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Player_id           Name    ig_fullname ig_username       ig_id  \\\n",
       "0         2     Al Horford     Al Horford   alhorford    10733526   \n",
       "1         4  Alan Anderson  Alan Anderson   dubblea74  1923491235   \n",
       "2         5       Alex Len       Alex Len  alexlen_21   300139600   \n",
       "\n",
       "                                              ig_bio  \\\n",
       "0                                                      \n",
       "1  Proud Father✊🏾\\n👨🏾‍🎓Michigan State Alumni\\n Hu...   \n",
       "2  Ukraine ✈️Maryland ✈️Phoenix ✈️Atlanta   \"A mo...   \n",
       "\n",
       "                                              ig_url ig_posts ig_followers  \\\n",
       "0  https://www.youtube.com/watch?v=YiZUWssMzyg&fe...      325       510621   \n",
       "1                    https://thecombinelasvegas.com/       80         5393   \n",
       "2                                               None      158        40823   \n",
       "\n",
       "  ig_following   ig_latestpost_time  \\\n",
       "0          265  2019-04-21 23:13:57   \n",
       "1           43  No post in 24 hours   \n",
       "2         1038  2019-04-22 02:56:56   \n",
       "\n",
       "                               ig_latestpost_caption  ig_latestpost_likes  \\\n",
       "0  Well done. On to the next challenge. Go Celtic...                21707   \n",
       "1                                No post in 24 hours  No post in 24 hours   \n",
       "2                             Somewhere in Barcelona                 1688   \n",
       "\n",
       "  ig_latestpost_comments ig_postwithin24hours  \n",
       "0                    214                    1  \n",
       "1    No post in 24 hours                    0  \n",
       "2                     16                    1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def post(name):\n",
    "\n",
    "    L = Instaloader()\n",
    "    posts =Profile.from_username(L.context, name).get_posts()\n",
    "    temp=pd.DataFrame()\n",
    "    SINCE = datetime.now()\n",
    "    UNTIL = datetime.now()- timedelta(days = 1)\n",
    "    x=0\n",
    "    for post in takewhile(lambda p: p.date > UNTIL, dropwhile(lambda p: p.date > SINCE, posts)):\n",
    "        tt = [post.date,post.caption,post.likes,post.comments]\n",
    "        temp=temp.append(tt)\n",
    "        x=x+1\n",
    "    else:\n",
    "        #tt=[np.NaN,np.NaN,np.NaN,np.NaN]\n",
    "        tt=['No post in 24 hours','No post in 24 hours','No post in 24 hours','No post in 24 hours']\n",
    "        temp=temp.append(tt)\n",
    "    return temp[0:4].transpose(),x\n",
    "\n",
    "# read players' ig username\n",
    "ig_n = pd.read_csv(\"player_ig2.csv\")\n",
    "L = Instaloader()\n",
    "\n",
    "ig_df=pd.DataFrame()\n",
    "iig_df=pd.DataFrame()\n",
    "\n",
    "for x in range(len(ig_n)):\n",
    "    try:\n",
    "        profile = Profile.from_username(L.context, ig_n.iat[x,2])\n",
    "\n",
    "        tt = pd.DataFrame(np.column_stack([ig_n.iat[x,0],ig_n.iat[x,1],\n",
    "                                           profile.full_name,profile.username, profile.userid,\n",
    "                                           profile.biography,profile.external_url,profile.mediacount,\n",
    "                                           profile.followers,profile.followees]))\n",
    "        ig_df=ig_df.append(tt)\n",
    "        zz=pd.DataFrame(np.column_stack([post(ig_n.iat[x,2])[0],post(ig_n.iat[x,2])[1]]))\n",
    "        iig_df=iig_df.append(zz)    \n",
    "    except:\n",
    "        print(x)\n",
    "ig_result = pd.concat([ig_df, iig_df], axis=1, ignore_index=True)\n",
    "ig_result.columns = ['Player_id','Name','ig_fullname','ig_username','ig_id','ig_bio','ig_url','ig_posts','ig_followers','ig_following',\n",
    "                 'ig_latestpost_time','ig_latestpost_caption','ig_latestpost_likes',\n",
    "                 'ig_latestpost_comments', 'ig_postwithin24hours']\n",
    "ig_result.index = range(0,len(ig_result))\n",
    "ig_result.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teams_Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_abbreviations</th>\n",
       "      <th>Team_fullname</th>\n",
       "      <th>Arena</th>\n",
       "      <th>Location</th>\n",
       "      <th>Capacity</th>\n",
       "      <th>Opened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MIA</td>\n",
       "      <td>Miami Heat</td>\n",
       "      <td>American Airlines Arena</td>\n",
       "      <td>Miami, Florida</td>\n",
       "      <td>19,600</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DAL</td>\n",
       "      <td>Dallas Mavericks</td>\n",
       "      <td>American Airlines Center</td>\n",
       "      <td>Dallas, Texas</td>\n",
       "      <td>19,200</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORL</td>\n",
       "      <td>Orlando Magic</td>\n",
       "      <td>Amway Center</td>\n",
       "      <td>Orlando, Florida</td>\n",
       "      <td>18,846</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Team_abbreviations     Team_fullname                     Arena  \\\n",
       "0                MIA        Miami Heat   American Airlines Arena   \n",
       "1                DAL  Dallas Mavericks  American Airlines Center   \n",
       "2                ORL     Orlando Magic              Amway Center   \n",
       "\n",
       "           Location Capacity  Opened  \n",
       "0    Miami, Florida   19,600    1999  \n",
       "1     Dallas, Texas   19,200    2001  \n",
       "2  Orlando, Florida   18,846    2010  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_profile = pd.read_csv(\"team_profile.csv\")\n",
    "team_profile.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization-- Table \"PROFILE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player_id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Birth_place</th>\n",
       "      <th>Birthdate</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AJ Price</td>\n",
       "      <td>29.0</td>\n",
       "      <td>us</td>\n",
       "      <td>October 7, 1986</td>\n",
       "      <td>185.0</td>\n",
       "      <td>81.45</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Aaron Brooks</td>\n",
       "      <td>30.0</td>\n",
       "      <td>us</td>\n",
       "      <td>January 14, 1985</td>\n",
       "      <td>180.0</td>\n",
       "      <td>72.45</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aaron Gordon</td>\n",
       "      <td>20.0</td>\n",
       "      <td>us</td>\n",
       "      <td>September 16, 1995</td>\n",
       "      <td>202.5</td>\n",
       "      <td>99.00</td>\n",
       "      <td>PF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Player_id          Name   Age Birth_place           Birthdate  Height  \\\n",
       "0          1      AJ Price  29.0          us     October 7, 1986   185.0   \n",
       "1          2  Aaron Brooks  30.0          us    January 14, 1985   180.0   \n",
       "2          3  Aaron Gordon  20.0          us  September 16, 1995   202.5   \n",
       "\n",
       "   Weight Position  \n",
       "0   81.45       PG  \n",
       "1   72.45       PG  \n",
       "2   99.00       PF  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table 'player_profile'\n",
    "# add player_id for primary key to represent the players name\n",
    "\n",
    "player_profile=nba3[['Name', 'Age','Birth_Place','Birthdate','Height','Weight','Pos']]\n",
    "player_profile.insert(0, 'Player_id', range(1,len(player_profile)+1))\n",
    "player_profile.columns =['Player_id','Name', 'Age','Birth_place','Birthdate','Height','Weight','Position'] \n",
    "player_profile.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_profile.to_csv('player_profile.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization-- Table \"TEAMS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_id</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>Fullname</th>\n",
       "      <th>Arena</th>\n",
       "      <th>Location</th>\n",
       "      <th>Capacity</th>\n",
       "      <th>Opened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>MIA</td>\n",
       "      <td>Miami Heat</td>\n",
       "      <td>American Airlines Arena</td>\n",
       "      <td>Miami, Florida</td>\n",
       "      <td>19,600</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>DAL</td>\n",
       "      <td>Dallas Mavericks</td>\n",
       "      <td>American Airlines Center</td>\n",
       "      <td>Dallas, Texas</td>\n",
       "      <td>19,200</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ORL</td>\n",
       "      <td>Orlando Magic</td>\n",
       "      <td>Amway Center</td>\n",
       "      <td>Orlando, Florida</td>\n",
       "      <td>18,846</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Team_id Abbreviation          Fullname                     Arena  \\\n",
       "0        1          MIA        Miami Heat   American Airlines Arena   \n",
       "1        2          DAL  Dallas Mavericks  American Airlines Center   \n",
       "2        3          ORL     Orlando Magic              Amway Center   \n",
       "\n",
       "           Location Capacity  Opened  \n",
       "0    Miami, Florida   19,600    1999  \n",
       "1     Dallas, Texas   19,200    2001  \n",
       "2  Orlando, Florida   18,846    2010  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table 'Teams'\n",
    "# add Team_id for primary key to represernt the team name\n",
    "\n",
    "teams=team_profile[:]\n",
    "teams.insert(0, 'Team_id', range(1,len(teams)+1))\n",
    "teams.columns =['Team_id','Abbreviation', 'Fullname','Arena','Location','Capacity','Opened']\n",
    "teams.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams.to_csv('teams.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization-- Table \"STAT_20xx_20xx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the player_profile and player_stat \n",
    "resulta = pd.merge(player_stat2015, player_profile, how='inner', on=['Name', 'Name'])\n",
    "resultb = pd.merge(player_stat2016, player_profile, how='inner', on=['Name', 'Name'])\n",
    "resultc = pd.merge(player_stat2017, player_profile, how='inner', on=['Name', 'Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ectract the data that ready to connect to Table\"Profile\" and also organize it into normal from\n",
    "stat_2014_2015=resulta[['Player_id', 'Team','PTS','RPG','AST','STL','BLK','TOV']]\n",
    "stat_2014_2015.columns =['Player_id','Team_id','PTS','RPG','AST','STL','BLK','TOV']\n",
    "stat_2015_2016=resultb[['Player_id', 'Team','PTS','RPG','AST','STL','BLK','TOV']]\n",
    "stat_2015_2016.columns =['Player_id','Team_id','PTS','RPG','AST','STL','BLK','TOV']\n",
    "stat_2016_2017=resultc[['Player_id', 'Team','PTS','RPG','AST','STL','BLK','TOV']]\n",
    "stat_2016_2017.columns =['Player_id','Team_id','PTS','RPG','AST','STL','BLK','TOV']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 'stat_20xx_20xx'\n",
    "# replace the team id instead of the team name for normalization\n",
    "\n",
    "for m in range(2015,2018):\n",
    "    globals()['stat_%s_%s' % (m-1,m)] = globals()['stat_%s_%s' % (m-1,m)][['Player_id','Team_id','PTS','RPG','AST','STL','BLK','TOV']]\n",
    "\n",
    "    globals()['stat_%s_%s' % (m-1,m)].columns = ['Player_id','Team_id','PTS','RPG','AST','STL','BLK','TOV']\n",
    "\n",
    "    for x in range(len(globals()['stat_%s_%s' % (m-1,m)])):\n",
    "        if globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='MIA': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=1\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='DAL': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=2\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='ORL': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=3\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='SAS': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=4\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='IND': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=5\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='BKN': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=6\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='WAS': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=7\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='OKC': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=8\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='MEM': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=9\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='MIL': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=10\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='SAC': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=11\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='DET': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=12\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='NYK': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=13\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='POR': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=14\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='GSW': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=15\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='DEN': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=16\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='CLE': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=17\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='TOR': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=18\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='NOP': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=19\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='CHA': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=20\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='LAC': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=21\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='LAL': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=22\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='ATL': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=23\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='PHX': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=24\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='MIN': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=25\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='BOS': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=26\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='HOU': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=27\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='CHI': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=28\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='UTA': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=29\n",
    "        elif globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=='PHI': globals()['stat_%s_%s' % (m-1,m)].iloc[x,1]=30\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output the stat files for 3 reason\n",
    "stat_2014_2015.to_csv('stat_2014_2015.csv',index=False)\n",
    "stat_2015_2016.to_csv('stat_2015_2016.csv',index=False)\n",
    "stat_2016_2017.to_csv('stat_2016_2017.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization-- Table \"IG_PROFILE\" and \"IG_POST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "## collect the data from instagram and organize it for nomalization\n",
    "\n",
    "# function for find the posts for the  playere who posted in recent one day\n",
    "def post(name):\n",
    "    L = Instaloader()\n",
    "    posts =Profile.from_username(L.context, name).get_posts()\n",
    "    temp=pd.DataFrame()\n",
    "    SINCE = datetime.now()\n",
    "    UNTIL = datetime.now()- timedelta(days = 1)\n",
    "\n",
    "    for post in takewhile(lambda p: p.date > UNTIL, dropwhile(lambda p: p.date > SINCE, posts)):\n",
    "        k=set(post.get_comments())\n",
    "        tt = [posts.userid,post.date,post.caption,post.likes,post.comments,list(k)[1][2]]\n",
    "        temp=temp.append(tt)\n",
    "    return temp\n",
    "\n",
    "# import the instagram account\n",
    "ig_n = pd.read_csv(\"player_ig2.csv\")\n",
    "\n",
    "L = Instaloader()\n",
    "ig_profile=pd.DataFrame()\n",
    "ig_post=pd.DataFrame()\n",
    "\n",
    "# make a table for posts\n",
    "for x in range(len(ig_n)):\n",
    "    try:\n",
    "        profile = Profile.from_username(L.context, ig_n.iat[x,2])\n",
    "        tt = pd.DataFrame(np.column_stack([ig_n.iat[x,0],\n",
    "                                           profile.full_name,profile.username, profile.userid,\n",
    "                                           profile.biography,profile.external_url,profile.mediacount,\n",
    "                                           profile.followers,profile.followees]))\n",
    "        ig_profile=ig_profile.append(tt)\n",
    "\n",
    "        a=post(ig_n.iat[x,2])\n",
    "        for y in range(0,len(a),5):\n",
    "            zz=pd.DataFrame(np.column_stack([a.iat[y,0],a.iat[y+1,0],a.iat[y+2,0],a.iat[y+3,0],a.iat[y+4,0],a.iat[y+5,0]]))\n",
    "            ig_post=ig_post.append(zz) \n",
    "    except:\n",
    "        print(x)\n",
    "\n",
    "# rename and insert the index(primary) for this table\n",
    "ig_post.insert(0, 'ig_post', range(1,len(ig_post)+1))\n",
    "ig_post.columns =['Postid','Userid','Time','Caption','Likes','Comments','Comment']\n",
    "ig_post.index = range(0,len(ig_post))\n",
    "ig_post['Time']= ig_post['Time'].astype('str')\n",
    "\n",
    "ig_profile.columns = ['Player_id','Fullname','Username','Userid','Bio','Url','Posts','Followers','Following']\n",
    "ig_profile.index = range(0,len(ig_profile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the file\n",
    "ig_post.head(3)\n",
    "ig_post.to_csv('ig_post.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the file\n",
    "ig_profile\n",
    "ig_profile.to_csv('ig_profile.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization-- Table \"IG_MOST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for finding the most popular posts and tages for last 30 days\n",
    "#\n",
    "\n",
    "def most(name):\n",
    "    L = Instaloader()\n",
    "    SINCE = datetime.now()\n",
    "    UNTIL = datetime.now()- timedelta(days = 30)\n",
    "    posts =Profile.from_username(L.context, name).get_posts()\n",
    "    \n",
    "    temp=[]\n",
    "    #for post in posts:\n",
    "    for post in takewhile(lambda p: p.date > UNTIL, dropwhile(lambda p: p.date > SINCE, posts)):\n",
    "        temp.extend(post.caption_hashtags)\n",
    "    if not temp:\n",
    "        p=[None,None,None,None,None]\n",
    "    else:\n",
    "        import collections\n",
    "        counter=collections.Counter(temp)\n",
    "        tags=pd.DataFrame()\n",
    "        for x in range(len(counter.most_common(5))):\n",
    "            test=pd.DataFrame([counter.most_common(5)[:][x]])\n",
    "            tags=tags.append(test)\n",
    "       \n",
    "        p= list(tags.loc[:,0])\n",
    "        if len(p) !=5:\n",
    "            for x in range(len(p),5):\n",
    "                p.insert(x, None)\n",
    "    \n",
    "    posts =Profile.from_username(L.context, name).get_posts()\n",
    "    q=[]\n",
    "    qwe=[]\n",
    "    for post in takewhile(lambda p: p.date > UNTIL, dropwhile(lambda p: p.date > SINCE, posts)):\n",
    "        qwe.append(post)\n",
    "    posts_sorted_by_likes = sorted(qwe, key = lambda p: p.likes + p.comments,reverse=True)\n",
    "    if not posts_sorted_by_likes:\n",
    "        q=['no post within 30 days']\n",
    "    else:\n",
    "        for post in islice(posts_sorted_by_likes, 0, 1):\n",
    "            q=[post.caption]\n",
    "    return p,q\n",
    "\n",
    "# import the instagram account\n",
    "ig_n = pd.read_csv(\"player_ig2.csv\")\n",
    "\n",
    "count =0\n",
    "L = Instaloader()\n",
    "ig_most=pd.DataFrame()\n",
    "\n",
    "# make a table for most popular hashtages and posts for last 30 days\n",
    "for x in range(len(ig_n)):\n",
    "    try:\n",
    "        profile = Profile.from_username(L.context, ig_n.iat[x,2])\n",
    "        a=most(ig_n.iat[x,2])\n",
    "        tt = pd.DataFrame(np.column_stack([profile.userid,a[0][0],a[0][1],a[0][2],a[0][3],a[0][4],a[1]]))\n",
    "        ig_most=ig_most.append(tt)\n",
    "        count=count+1\n",
    "    except:\n",
    "        # if error occured show which one failed\n",
    "        print(ig_n.iat[x,2])\n",
    "\n",
    "# rename the columns\n",
    "ig_most.columns = ['Userid','tag1','tag2','tag3','tag4','tag5','Most_popular_post']\n",
    "ig_most.index = range(0,len(ig_most))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Userid</th>\n",
       "      <th>Most_popular_hashtag</th>\n",
       "      <th>Most_popular_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10733526</td>\n",
       "      <td>risetogether</td>\n",
       "      <td>My favorite time of year: playoff season! Runn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1923491235</td>\n",
       "      <td>marchmadness</td>\n",
       "      <td>It’s almost that time....I’m not looking at du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300139600</td>\n",
       "      <td>beststeakhousehandsdown</td>\n",
       "      <td>End of Chapter 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>375417881</td>\n",
       "      <td>goat</td>\n",
       "      <td>Too many ppl don’t understand but Notre Dame i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8174195</td>\n",
       "      <td>str8up</td>\n",
       "      <td>Praying for my bro and his family Ishallah you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37867524</td>\n",
       "      <td>no hashtag within 30 days</td>\n",
       "      <td>no post within 30 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24949656</td>\n",
       "      <td>detroitbasketball</td>\n",
       "      <td>PLAYOFFS! 🦍🦍🦍\\n#DetroitBasketball 📸: @iamtailz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6246343</td>\n",
       "      <td>no hashtag within 30 days</td>\n",
       "      <td>Chapter 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>305609563</td>\n",
       "      <td>no hashtag within 30 days</td>\n",
       "      <td>no post within 30 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3518326383</td>\n",
       "      <td>no hashtag within 30 days</td>\n",
       "      <td>no post within 30 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36118956</td>\n",
       "      <td>no hashtag within 30 days</td>\n",
       "      <td>Ready for opening day!! ⚾️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13516273</td>\n",
       "      <td>ripnipthegreat</td>\n",
       "      <td>😢 If you know me and follow me you know how i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>218386695</td>\n",
       "      <td>nbaplayoffs</td>\n",
       "      <td>Boston ✈️ Indiana. Little fella lovin’ the new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2031038549</td>\n",
       "      <td>no hashtag within 30 days</td>\n",
       "      <td>no post within 30 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>54752764</td>\n",
       "      <td>no hashtag within 30 days</td>\n",
       "      <td>🚀</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Userid       Most_popular_hashtag  \\\n",
       "0     10733526               risetogether   \n",
       "1   1923491235               marchmadness   \n",
       "2    300139600    beststeakhousehandsdown   \n",
       "3    375417881                       goat   \n",
       "4      8174195                     str8up   \n",
       "5     37867524  no hashtag within 30 days   \n",
       "6     24949656          detroitbasketball   \n",
       "7      6246343  no hashtag within 30 days   \n",
       "8    305609563  no hashtag within 30 days   \n",
       "9   3518326383  no hashtag within 30 days   \n",
       "10    36118956  no hashtag within 30 days   \n",
       "11    13516273             ripnipthegreat   \n",
       "12   218386695                nbaplayoffs   \n",
       "13  2031038549  no hashtag within 30 days   \n",
       "14    54752764  no hashtag within 30 days   \n",
       "\n",
       "                                    Most_popular_post  \n",
       "0   My favorite time of year: playoff season! Runn...  \n",
       "1   It’s almost that time....I’m not looking at du...  \n",
       "2                                    End of Chapter 6  \n",
       "3   Too many ppl don’t understand but Notre Dame i...  \n",
       "4   Praying for my bro and his family Ishallah you...  \n",
       "5                              no post within 30 days  \n",
       "6      PLAYOFFS! 🦍🦍🦍\\n#DetroitBasketball 📸: @iamtailz  \n",
       "7                                       Chapter 15...  \n",
       "8                              no post within 30 days  \n",
       "9                              no post within 30 days  \n",
       "10                         Ready for opening day!! ⚾️  \n",
       "11  😢 If you know me and follow me you know how i ...  \n",
       "12  Boston ✈️ Indiana. Little fella lovin’ the new...  \n",
       "13                             no post within 30 days  \n",
       "14                                                  🚀  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ig_most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_most\n",
    "ig_most.to_csv('ig_most.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citations\n",
    "1. https://github.com/nikbearbrown/INFO_6210/blob/master/Week_2/NBB_IMDB_Web_Scraper.ipynb\n",
    "2. https://github.com/danielfrg/espn-nba-scrapy/blob/master/src/scrap/get_players.py\n",
    "3. http://www.gregreda.com/2015/02/15/web-scraping-finding-the-api/\n",
    "4. http://savvastjortjoglou.com/nba-shot-sharts.html\n",
    "5. https://instaloader.github.io/index.html\n",
    "6. https://sebastianraschka.com/Articles/2014_sqlite_in_python_tutorial.html\n",
    "7. http://www.dcs.bbk.ac.uk/~ptw/teaching/DBM/er.pdf\n",
    "8. https://www.dataquest.io/blog/python-pandas-databases/\n",
    "9. https://github.com/nikbearbrown/INFO_6210/tree/master/Lahmans_Baseball_Database\n",
    "\n",
    "Data source links:  \n",
    "1. ESPN: http://www.espn.com/nba/statistics/player/_/stat/rebounds/sort/avgRebounds/year/2015/count/\n",
    "2. NBA: https://stats.nba.com/leaders/?Season=2014-15&SeasonType=Regular%20Season\n",
    "3. Kaggle: https://www.kaggle.com/drgilermo/nba-players-stats-20142015/version/1\n",
    "4. Instagram: https://www.instagram.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contribution\n",
    "This assignment is 95% done by my own, and 5% of the information and code that help me to do this assignment are from the Internet as the citations shown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License\n",
    "Copyright 2019\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
