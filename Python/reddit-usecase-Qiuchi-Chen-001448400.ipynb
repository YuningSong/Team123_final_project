{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import reddit_comment table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "https://github.com/nikbearbrown/INFO_6210/blob/master/Week_2/NBB_IMDB_Web_Scraper.ipynb\n",
    "https://github.com/danielfrg/espn-nba-scrapy/blob/master/src/scrap/get_players.py\n",
    "http://www.gregreda.com/2015/02/15/web-scraping-finding-the-api/\n",
    "http://savvastjortjoglou.com/nba-shot-sharts.html\n",
    "https://instaloader.github.io/index.html\n",
    "https://sebastianraschka.com/Articles/2014_sqlite_in_python_tutorial.html\n",
    "http://www.dcs.bbk.ac.uk/~ptw/teaching/DBM/er.pdf\n",
    "https://www.dataquest.io/blog/python-pandas-databases/\n",
    "https://github.com/nikbearbrown/INFO_6210/tree/master/Lahmans_Baseball_Database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License\n",
    "Copyright 2019 \n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contribution\n",
    "This assignment is 100% done by our team, and 5% of the information and code that help me to do this assignment are from the Internet as the citations shown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read csv file first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_csv=pd.read_csv(\"reddit_comment.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer the csv file to the pandas dataframe for the following operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_df = pd.DataFrame(rc_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_df=rc_df.astype(object,int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build connection with the database and create cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "db1 = '/Users/rachealchen/Documents/jupyter/6210FinalProject/UPF/reddit_comment.db' \n",
    "conn1 = sqlite3.connect(db1) \n",
    "c1 = conn1.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creat reddit_comment table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_df.to_sql('reddit_comment',             # Name of the table.\n",
    "            con=conn1,                    # The handle to the file that is set up.\n",
    "            if_exists='replace',         # Overwrite, append, or fail.\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the columns in the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'index', 'INTEGER', 0, None, 0)\n",
      "(1, 'PlayerID', 'INTEGER', 0, None, 0)\n",
      "(2, 'name', 'TEXT', 0, None, 0)\n",
      "(3, 'body', 'TEXT', 0, None, 0)\n",
      "(4, 'score', 'INTEGER', 0, None, 0)\n",
      "(5, 'author', 'TEXT', 0, None, 0)\n",
      "(6, 'id', 'TEXT', 0, None, 0)\n",
      "(7, 'created', 'INTEGER', 0, None, 0)\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for row in conn1.execute(\"pragma table_info('reddit_comment')\").fetchall():\n",
    "    print (row)\n",
    "print(len(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import reddit_latest table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read csv file first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_csv=pd.read_csv(\"reddit_latest.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer the csv file to the pandas dataframe for the following operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_df = pd.DataFrame(rl_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_df=rl_df.astype(object,int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build connection with the database and create cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "db2 = '/Users/rachealchen/Documents/jupyter/6210FinalProject/UPF/reddit_latest.db' \n",
    "conn2 = sqlite3.connect(db1) \n",
    "c2 = conn2.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creat reddit_comment table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_df.to_sql('reddit_latest',             # Name of the table.\n",
    "            con=conn2,                    # The handle to the file that is set up.\n",
    "            if_exists='replace',         # Overwrite, append, or fail.\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the columns in the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'index', 'INTEGER', 0, None, 0)\n",
      "(1, 'PlayerID', 'INTEGER', 0, None, 0)\n",
      "(2, 'name', 'TEXT', 0, None, 0)\n",
      "(3, 'title', 'TEXT', 0, None, 0)\n",
      "(4, 'score', 'INTEGER', 0, None, 0)\n",
      "(5, 'author', 'TEXT', 0, None, 0)\n",
      "(6, 'author_id', 'TEXT', 0, None, 0)\n",
      "(7, 'url', 'TEXT', 0, None, 0)\n",
      "(8, 'comms_num', 'INTEGER', 0, None, 0)\n",
      "(9, 'created', 'INTEGER', 0, None, 0)\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for row in conn2.execute(\"pragma table_info('reddit_latest')\").fetchall():\n",
    "    print (row)\n",
    "print(len(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start writing usecases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Select the comments have high score and the target player ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Andre Iguodala',\n",
       "  \"1. That's nice of Andre\\n\\n2. It's extremely fucked that a grandmother needs to pay $7500 to adopt her own fuckin grandkids\"),\n",
       " ('Hollis Thompson',\n",
       "  'iâ€™m very conflicted. not only is this shitting on the celtics, itâ€™s praising the lakers. i really donâ€™t know how to feel. '),\n",
       " ('James Jones',\n",
       "  'The beef with Dudley of all players is so hilarious to me. This series man'),\n",
       " ('Jordan Adams',\n",
       "  'It is hypocrotical but its also very easy to see why the NBA wants him to play. Nobody buys a ticket or tunes into a game to watch Melo or JR, they do for AD.'),\n",
       " ('Langston Galloway', 'Na-cho night dubs fans'),\n",
       " ('Robbie Hummel', '21 assists, two turnovers :o')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = c1.execute(\"SELECT name, body FROM reddit_comment where score > 5000;\")\n",
    "q=results.fetchall() \n",
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Select comment which may contain a bad mood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"And now I'm crying at workðŸ˜­\\n\\nWay to show out for the fallen Magic men that've shown their love and support.\",)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2 = c1.execute(\"SELECT body FROM reddit_comment where body like '%cry%';\")\n",
    "q2=results2.fetchall() \n",
    "q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Select author who has the lowest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('SportsPi',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('SportsPi',),\n",
       " ('okcthunder_13pg',),\n",
       " ('KeepingDankMemesDank',),\n",
       " ('SportsPi',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('f1uk3r',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('IamOlderthanMe',),\n",
       " ('AutoModerator',),\n",
       " ('arg061000',),\n",
       " ('robot301_01',),\n",
       " ('AutoModerator',),\n",
       " ('nick168',),\n",
       " ('AutoModerator',),\n",
       " ('TheGreatZarquon',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('edgykitty',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('IamOlderthanMe',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('robot301_03',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('lavta',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('AutoModerator',),\n",
       " ('nick168',),\n",
       " ('nick168',),\n",
       " ('AutoModerator',)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results3 = c1.execute(\"SELECT author FROM reddit_comment where score=1;\")\n",
    "q3=results3.fetchall() \n",
    "q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Select target player name for the title which may contain a good mood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Kawhi Leonard',),\n",
       " ('Nazr Mohammed',),\n",
       " ('Nick Johnson',),\n",
       " ('Nikola Pekovic',),\n",
       " ('Shawn Marion',),\n",
       " ('Will Barton',)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results4 = c2.execute(\"SELECT name FROM reddit_latest where title like '%great%';\")\n",
    "q4=results4.fetchall() \n",
    "q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Select target player for surprising mood title, sort by player id in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Tarik Black',),\n",
       " ('Shayne Whittington',),\n",
       " ('Sean Kilpatrick',),\n",
       " ('Rudy Gay',),\n",
       " ('Ronny Turiaf',),\n",
       " ('Quincy Miller',),\n",
       " ('Nick Johnson',),\n",
       " ('Nene',),\n",
       " ('Nazr Mohammed',),\n",
       " ('Nate Robinson',),\n",
       " ('Meyers Leonard',),\n",
       " ('Maurice Harkless',),\n",
       " ('Marcus Thornton',),\n",
       " ('Marco Belinelli',),\n",
       " ('Larry Sanders',),\n",
       " ('Kent Bazemore',),\n",
       " (\"Johnny O'Bryant III\",),\n",
       " ('Jeremy Lamb',),\n",
       " ('Jeremy Evans',),\n",
       " ('James Young',),\n",
       " ('Jamal Crawford',),\n",
       " ('Elijah Millsap',),\n",
       " ('Ekpe Udoh',),\n",
       " ('Derrick Favors',),\n",
       " ('Danilo Gallinari',),\n",
       " ('Charlie Villanueva',),\n",
       " ('Bruno Caboclo',),\n",
       " ('Archie Goodwin',),\n",
       " ('Anthony Bennett',),\n",
       " ('Andrew Nicholson',),\n",
       " (\"Amar'e Stoudemire\",)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results5 = c2.execute(\"SELECT name FROM reddit_latest where title like '%!%' ORDER BY PlayerID DESC ;\")\n",
    "q5=results5.fetchall() \n",
    "q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
